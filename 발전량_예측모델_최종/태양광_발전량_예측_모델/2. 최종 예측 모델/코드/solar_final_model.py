# -*- coding: utf-8 -*-
import math
from datetime import datetime, timedelta
import pandas as pd
import requests
import joblib
import numpy as np
import pytz
import pvlib
import calendar
import matplotlib.pyplot as plt
from matplotlib import font_manager
import os
# ==============================================================================
# ì„¤ì • (Configurations)
# ==============================================================================
# ê²½ë¡œ ì„¤ì • (ê³µëª¨ì „ìš© ìƒëŒ€ê²½ë¡œ)
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG = {
    "api": {
        "service_key": "zJLFmDMckurk+au32kOHTxsrU5gG2NAadNE68xYaBW8PBJtdXN7F4QEpuW6f68GL0qLcMQsmgyPHxbOs43NCBA==",
        "base_url": "http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst"
    },
    "files": {
        "grid_mapping_csv": os.path.join(BASE_DIR, "..", "data", "ê²©ìì˜ˆë³´_ê´€ì¸¡ì§€ì ë§¤í•‘.csv"),
        "insolation_model_path": os.path.join(BASE_DIR, "..", "data", "ì¼ì‚¬ëª¨ë¸.joblib"),
        "power_model_path": os.path.join(BASE_DIR, "..", "data", "íƒœì–‘ê´‘_ë°œì „ëŸ‰_ëª¨ë¸.joblib"),
        "output_csv": os.path.join(BASE_DIR, "..", "ì‹¤í–‰ ê²°ê³¼", "solar_prediction_results_final.csv")
    }
}

# ==============================================================================
# ê³„ì‚° í•¨ìˆ˜ (Calculation Functions)
# ==============================================================================
def calculate_age(base_date_str: str, built_date_str: str) -> float:
    """ê¸°ì¤€ì¼ê³¼ ì¤€ê³µì¼ë¡œ ì„¤ë¹„ ì—°ì‹(ë…„) ê³„ì‚°"""
    try:
        base_date = datetime.strptime(base_date_str, '%Y%m%d')
        built_date = datetime.strptime(built_date_str, '%Y%m%d')
        return round((base_date - built_date).days / 365.25, 2)
    except ValueError:
        print(f"âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤: {base_date_str} ë˜ëŠ” {built_date_str}. YYYYMMDD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        exit()

def calculate_dew_point(temp_celsius: float, rh_percent: float) -> float:
    """ê¸°ì˜¨(Â°C)ê³¼ ìƒëŒ€ìŠµë„(%)ë¡œ ì´ìŠ¬ì ì˜¨ë„(Â°C) ê³„ì‚°"""
    b, c = 17.62, 243.12
    rh_percent = max(rh_percent, 0.1)
    gamma = (b * temp_celsius / (c + temp_celsius)) + np.log(rh_percent / 100.0)
    return (c * gamma) / (b - gamma)

# ==============================================================================
# í•µì‹¬ ë¡œì§ í•¨ìˆ˜ (Core Logic Functions)
# ==============================================================================

def get_latest_base_time():
    """í˜„ì¬ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ìµœì‹ ì˜ base_dateì™€ base_timeì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    now = datetime.now()
    available_times = ['02', '05', '08', '11', '14', '17', '20', '23']
    current_hour = now.hour
    current_date = now.strftime('%Y%m%d')
    latest_time = None
    for time_str in reversed(available_times):
        if current_hour >= int(time_str):
            latest_time = time_str + '00'
            break
    if latest_time is None:
        yesterday = now - pd.Timedelta(days=1)
        current_date = yesterday.strftime('%Y%m%d')
        latest_time = '2300'
    print(f"í˜„ì¬ ì‹œê°„: {now.strftime('%Y-%m-%d %H:%M')}")
    print(f"ì„ íƒëœ ê¸°ì¤€ì¼ì‹œ: {current_date} {latest_time}")
    return current_date, latest_time

def get_user_inputs(base_date: str) -> dict:
    """ì‚¬ìš©ìë¡œë¶€í„° ì˜ˆì¸¡ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤."""
    print("--- íƒœì–‘ê´‘ ë°œì „ëŸ‰ ì˜ˆì¸¡ ì •ë³´ ì…ë ¥ ---")
    try:
        grid_df = pd.read_csv(CONFIG['files']['grid_mapping_csv'])
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: ë§¤í•‘ íŒŒì¼ '{CONFIG['files']['grid_mapping_csv']}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    # ì£¼ì†Œ ì„ íƒ ë¡œì§
    step1_list = grid_df['1ë‹¨ê³„'].dropna().unique().tolist()
    print("\n[1ë‹¨ê³„] ì‹œ/ë„ ì„ íƒ:")
    for i, s1 in enumerate(step1_list): print(f"{i+1}. {s1}")
    try:
        s1_idx = int(input(f"â†’ 1ë‹¨ê³„ ë²ˆí˜¸ ì…ë ¥(1~{len(step1_list)}): ")) - 1
        s1_val = step1_list[s1_idx]
        step2_list = grid_df[grid_df['1ë‹¨ê³„'] == s1_val]['2ë‹¨ê³„'].dropna().unique().tolist()
        print("\n[2ë‹¨ê³„] ì‹œ/êµ°/êµ¬ ì„ íƒ:")
        for i, s2 in enumerate(step2_list): print(f"{i+1}. {s2}")
        s2_idx = int(input(f"â†’ 2ë‹¨ê³„ ë²ˆí˜¸ ì…ë ¥(1~{len(step2_list)}): ")) - 1
        s2_val = step2_list[s2_idx]
        step3_list = grid_df[(grid_df['1ë‹¨ê³„'] == s1_val) & (grid_df['2ë‹¨ê³„'] == s2_val)]['3ë‹¨ê³„'].dropna().unique().tolist()
        print("\n[3ë‹¨ê³„] ì/ë©´/ë™ ì„ íƒ:")
        for i, s3 in enumerate(step3_list): print(f"{i+1}. {s3}")
        s3_idx = int(input(f"â†’ 3ë‹¨ê³„ ë²ˆí˜¸ ì…ë ¥(1~{len(step3_list)}): ")) - 1
        s3_val = step3_list[s3_idx]
    except (ValueError, IndexError):
        print("âŒ ë¶€ì ì ˆí•œ ê°’ì´ ì…ë ¥ë˜ì–´ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit()
    
    row = grid_df[(grid_df['1ë‹¨ê³„'] == s1_val) & (grid_df['2ë‹¨ê³„'] == s2_val) & (grid_df['3ë‹¨ê³„'] == s3_val)]
    if row.empty:
        print("âŒ í•´ë‹¹ í–‰ì •êµ¬ì—­ì˜ ì¢Œí‘œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()
    
    # ì„¤ë¹„ ì •ë³´ ì…ë ¥
    try:
        capacity = float(input("\nğŸ”§ ì„¤ë¹„ìš©ëŸ‰(MW)ì„ ì…ë ¥í•˜ì„¸ìš”: "))
        built_date = input("ğŸ—ï¸ ì¤€ê³µì¼ìë¥¼ ì…ë ¥í•˜ì„¸ìš” (YYYYMMDD í˜•ì‹): ")
    except ValueError:
        print("âŒ ì„¤ë¹„ìš©ëŸ‰ì€ ìˆ«ìë¡œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
        exit()

    inputs = {
        'nx': int(row['ê²©ì X'].iloc[0]), 'ny': int(row['ê²©ì Y'].iloc[0]),
        'ìœ„ë„': float(row['ìœ„ë„'].iloc[0]), 'ê²½ë„': float(row['ê²½ë„'].iloc[0]),
        'ê³ ë„': float(row['ë…¸ì¥í•´ë°œê³ ë„(m)'].iloc[0]), 'ì„¤ë¹„ìš©ëŸ‰(MW)': capacity,
        'ì—°ì‹(ë…„)': calculate_age(base_date, built_date)
    }
    print("-" * 20)
    return inputs

def get_weather_forecast(params: dict) -> list | None:
    """ê¸°ìƒì²­ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì˜ˆë³´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    api_config = CONFIG['api']
    api_params = {'serviceKey': api_config['service_key'], 'pageNo': '1', 'numOfRows': '1000', 'dataType': 'JSON', **params}
    try:
        print("ğŸ“¡ ê¸°ìƒì²­ APIì—ì„œ ì˜ˆë³´ ë°ì´í„°ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
        response = requests.get(api_config['base_url'], params=api_params, timeout=30)
        response.raise_for_status()
        data = response.json()
        if data['response']['header']['resultCode'] != '00':
            print(f"âŒ API ì˜¤ë¥˜: {data['response']['header']['resultMsg']}")
            return None
        print("âœ… API í˜¸ì¶œ ì„±ê³µ!")
        return data['response']['body']['items'].get('item', [])
    except requests.exceptions.RequestException as e:
        print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None

def process_weather_data(items: list, location_info: dict) -> pd.DataFrame:
    """API ì‘ë‹µì„ íŒŒì‹±í•˜ê³  ëª¨ë¸ì— í•„ìš”í•œ ê¸°ë³¸ í”¼ì²˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if not items: return pd.DataFrame()
    df = pd.DataFrame(items)
    df['fcstValue'] = pd.to_numeric(df['fcstValue'], errors='coerce')
    pivot_df = df.pivot_table(index=['fcstDate', 'fcstTime'], columns='category', values='fcstValue').reset_index()
    rename_dict = {'TMP': 'ê¸°ì˜¨(Â°C)', 'PCP': 'ê°•ìˆ˜ëŸ‰(mm)', 'REH': 'ìŠµë„(%)', 'WSD': 'í’ì†(m/s)', 'SNO': 'ì ì„¤(cm)', 'SKY': 'í•˜ëŠ˜ìƒíƒœ'}
    pivot_df.rename(columns=rename_dict, inplace=True)
    pivot_df.fillna(0, inplace=True)
    seoul_tz = pytz.timezone('Asia/Seoul')
    pivot_df['datetime'] = pd.to_datetime(pivot_df['fcstDate'] + pivot_df['fcstTime'], format='%Y%m%d%H%M').dt.tz_localize(seoul_tz)
    
    pivot_df['month'] = pivot_df['datetime'].dt.month
    pivot_df['hour'] = pivot_df['datetime'].dt.hour
    pivot_df['month_sin'] = np.sin(2 * np.pi * pivot_df['month'] / 12)
    pivot_df['month_cos'] = np.cos(2 * np.pi * pivot_df['month'] / 12)
    pivot_df['hour_sin'] = np.sin(2 * np.pi * pivot_df['hour'] / 24)
    pivot_df['hour_cos'] = np.cos(2 * np.pi * pivot_df['hour'] / 24)
    pivot_df['days_in_month'] = pivot_df['datetime'].dt.days_in_month
    pivot_df['month_day'] = pivot_df['datetime'].dt.month + (pivot_df['datetime'].dt.day - 1) / pivot_df['days_in_month']
    pivot_df['month_day_sin'] = np.sin(2 * np.pi * pivot_df['month_day'] / 12)
    pivot_df['month_day_cos'] = np.cos(2 * np.pi * pivot_df['month_day'] / 12)
    pivot_df['ì´ìŠ¬ì '] = pivot_df.apply(lambda row: calculate_dew_point(row['ê¸°ì˜¨(Â°C)'], row['ìŠµë„(%)']), axis=1)
    pivot_df['T-Td'] = pivot_df['ê¸°ì˜¨(Â°C)'] - pivot_df['ì´ìŠ¬ì ']
    
    for key, value in location_info.items(): pivot_df[key] = value
    print("âœ… ë°ì´í„° ì²˜ë¦¬ ë° ê¸°ë³¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ.")
    return pivot_df

def add_solar_position_features(df: pd.DataFrame) -> pd.DataFrame:
    """pvlibë¥¼ ì‚¬ìš©í•˜ì—¬ íƒœì–‘ê³ ë„ì™€ ë°©ìœ„ê°ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    print("â³ íƒœì–‘ê³ ë„ ë° ë°©ìœ„ê° ê³„ì‚° ì¤‘ (pvlib ì‚¬ìš©)...")
    loc = pvlib.location.Location(latitude=df['ìœ„ë„'].iloc[0], longitude=df['ê²½ë„'].iloc[0], tz='Asia/Seoul', altitude=df['ê³ ë„'].iloc[0])
    solar_positions = loc.get_solarposition(times=df['datetime'])
    df['íƒœì–‘ê³ ë„'] = solar_positions['apparent_elevation'].values
    df['ë°©ìœ„ê°'] = solar_positions['azimuth'].values
    print("âœ… íƒœì–‘ê³ ë„ ë° ë°©ìœ„ê° ê³„ì‚° ì™„ë£Œ.")
    return df

def predict_insolation(df: pd.DataFrame) -> pd.DataFrame:
    """2-Step ëª¨ë¸(ë¶„ë¥˜+íšŒê·€)ì„ ì‚¬ìš©í•˜ì—¬ ì¼ì‚¬ëŸ‰ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    print(f"\nëª¨ë¸ ë¡œë”© (ì¼ì‚¬ëŸ‰ 2-Step): '{CONFIG['files']['insolation_model_path']}'")
    try:
        model_dict = joblib.load(CONFIG['files']['insolation_model_path'])
        classifier = model_dict['classifier']
        regressor = model_dict['regressor']
    except (FileNotFoundError, KeyError) as e:
        print(f"âŒ ì¼ì‚¬ëŸ‰ ëª¨ë¸ íŒŒì¼ ë¡œë”© ì˜¤ë¥˜: {e}. ì˜ˆì¸¡ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return pd.DataFrame()

    # ì¼ì‚¬ëŸ‰ ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” í”¼ì²˜ ëª©ë¡
    feature_cols = [
        'month_day_sin', 'month_day_cos', 'hour_sin', 'hour_cos',
        'íƒœì–‘ê³ ë„', 'ë°©ìœ„ê°', 'ê¸°ì˜¨(Â°C)', 'í’ì†(m/s)', 'ìŠµë„(%)',
        'ê°•ìˆ˜ëŸ‰(mm)', 'í•˜ëŠ˜ìƒíƒœ', 'T-Td'
    ]
    
    input_df = df[feature_cols].copy()
    input_df['í•˜ëŠ˜ìƒíƒœ'] = input_df['í•˜ëŠ˜ìƒíƒœ'].astype('category')

    print("ğŸŒ¤ï¸ ì¼ì‚¬ëŸ‰ ì˜ˆì¸¡ ì¤‘ (1/2: ë¶„ë¥˜ ëª¨ë¸)...")
    is_zero_pred = classifier.predict(input_df)

    print("ğŸŒ¤ï¸ ì¼ì‚¬ëŸ‰ ì˜ˆì¸¡ ì¤‘ (2/2: íšŒê·€ ëª¨ë¸)...")
    final_pred = np.zeros(len(input_df))
    idx_nonzero = np.where(is_zero_pred == 0)[0]
    
    if len(idx_nonzero) > 0:
        # --- ì—¬ê¸°ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤ ---
        try:
            # ì›ë³¸ ë¡œì§: .booster_.predict() ì‚¬ìš©ì„ ìš°ì„  ì‹œë„
            pred_real = regressor.booster_.predict(input_df.iloc[idx_nonzero])
        except AttributeError:
            # .booster_ ì†ì„±ì´ ì—†ëŠ” ê²½ìš°, ì¼ë°˜ .predict() ì‚¬ìš©
            print("   - (ì •ë³´) .booster_ ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ .predict()ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            pred_real = regressor.predict(input_df.iloc[idx_nonzero])
        # --- ì—¬ê¸°ê¹Œì§€ ìˆ˜ì • ---
        
        final_pred[idx_nonzero] = np.clip(pred_real, 0, None)

    df['ì¼ì‚¬(MJ/m2)'] = final_pred
    print("âœ… ì¼ì‚¬ëŸ‰ ì˜ˆì¸¡ ì™„ë£Œ.")
    return df

def predict_power_generation(df: pd.DataFrame) -> np.ndarray | None:
    """2-Step ëª¨ë¸(ë¶„ë¥˜+íšŒê·€)ì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë°œì „ íš¨ìœ¨ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤."""
    print(f"\nëª¨ë¸ ë¡œë”© (ìµœì¢… ë°œì „ëŸ‰ 2-Step): '{CONFIG['files']['power_model_path']}'")
    try:
        model_dict = joblib.load(CONFIG['files']['power_model_path'])
        classifier = model_dict['classifier']
        regressor = model_dict['regressor']
        feature_cols = model_dict['features']
    except (FileNotFoundError, KeyError) as e:
        print(f"âŒ ìµœì¢… ë°œì „ëŸ‰ ëª¨ë¸ íŒŒì¼ ë¡œë”© ì˜¤ë¥˜: {e}. ì˜ˆì¸¡ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return None

    # ëª¨ë¸ì— í•„ìš”í•œ í”¼ì²˜ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
    missing_cols = [col for col in feature_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ ìµœì¢… ëª¨ë¸ì— í•„ìš”í•œ í”¼ì²˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {missing_cols}")
        return None

    input_df = df[feature_cols].copy()
    
    # --- ì—¬ê¸°ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤ ---
    # ìµœì¢… ëª¨ë¸ì˜ í•™ìŠµ ë°©ì‹ì— ë§ì¶° 'í•˜ëŠ˜ìƒíƒœ' ì»¬ëŸ¼ì„ ì •ìˆ˜í˜•(int)ìœ¼ë¡œë§Œ ìœ ì§€í•©ë‹ˆë‹¤.
    # .astype('category') ë³€í™˜ì„ ì œê±°í•©ë‹ˆë‹¤.
    input_df['í•˜ëŠ˜ìƒíƒœ'] = input_df['í•˜ëŠ˜ìƒíƒœ'].astype('int')
    # --------------------------

    print("ğŸ”‹ ìµœì¢… ë°œì „ëŸ‰ ì˜ˆì¸¡ ì¤‘ (1/2: ë¶„ë¥˜)...")
    is_zero_pred = classifier.predict(input_df)
    print("ğŸ”‹ ìµœì¢… ë°œì „ëŸ‰ ì˜ˆì¸¡ ì¤‘ (2/2: íšŒê·€)...")
    final_pred_efficiency = np.zeros(len(input_df))
    idx_nonzero = np.where(is_zero_pred == 0)[0]

    if len(idx_nonzero) > 0:
        pred_log = regressor.predict(input_df.iloc[idx_nonzero])
        pred_real = np.expm1(pred_log)
        final_pred_efficiency[idx_nonzero] = np.clip(pred_real, 0, None)

    print("âœ… ìµœì¢… ë°œì „ëŸ‰(íš¨ìœ¨) ì˜ˆì¸¡ ì™„ë£Œ.")
    return final_pred_efficiency

def calculate_daily_totals(result_df: pd.DataFrame) -> pd.DataFrame:
    """ì¼ë³„ ì´ ë°œì „ëŸ‰ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    result_df['date'] = pd.to_datetime(result_df['datetime']).dt.date
    daily_totals = result_df.groupby('date')['ì˜ˆì¸¡ë°œì „ëŸ‰(kWh)'].sum().reset_index()
    daily_totals['date'] = daily_totals['date'].astype(str)
    daily_totals['day_name'] = pd.to_datetime(daily_totals['date']).dt.strftime('%Y-%m-%d (%A)')
    
    # ì˜¤ëŠ˜, ë‚´ì¼, ëª¨ë ˆ êµ¬ë¶„
    today = datetime.now().date()
    daily_totals['day_type'] = daily_totals['date'].apply(lambda x: 
        'ì˜¤ëŠ˜' if pd.to_datetime(x).date() == today else
        'ë‚´ì¼' if pd.to_datetime(x).date() == today + pd.Timedelta(days=1) else
        'ëª¨ë ˆ' if pd.to_datetime(x).date() == today + pd.Timedelta(days=2) else
        'ê¸°íƒ€'
    )
    return daily_totals

def print_daily_totals(daily_totals: pd.DataFrame):
    """ì¼ë³„ ì´ ë°œì „ëŸ‰ ì¤‘ ë‚´ì¼/ëª¨ë ˆë§Œ í„°ë¯¸ë„ì— ì¶œë ¥í•©ë‹ˆë‹¤."""
    print("\n" + "="*50)
    print("ğŸ“Š ì¼ë³„ ì´ ë°œì „ëŸ‰ ì˜ˆì¸¡ (ë‚´ì¼/ëª¨ë ˆë§Œ)")
    print("="*50)
    
    for _, row in daily_totals.iterrows():
        day_type = row['day_type']
        total_kwh = row['ì˜ˆì¸¡ë°œì „ëŸ‰(kWh)']
        date_str = row['day_name']
        
        if day_type in ['ë‚´ì¼', 'ëª¨ë ˆ']:
            print(f"ğŸ”¹ {day_type} ({date_str}): {total_kwh:,.2f} kWh")
    
    print("="*50)

def show_hourly_generation_graph(result_df: pd.DataFrame):
    """ì‹œê°„ë³„ ë°œì „ëŸ‰ êº¾ì€ì„ ê·¸ë˜í”„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    try:
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows ê¸°ë³¸ í•œê¸€ í°íŠ¸
        plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
        
        # ë°ì´í„° ì¤€ë¹„
        result_df['date'] = pd.to_datetime(result_df['datetime']).dt.date
        result_df = result_df.sort_values('datetime')
        
        # ì˜¤ëŠ˜, ë‚´ì¼, ëª¨ë ˆ ë°ì´í„°ë§Œ í•„í„°ë§
        today = datetime.now().date()
        target_dates = [today, today + pd.Timedelta(days=1), today + pd.Timedelta(days=2)]
        filtered_df = result_df[result_df['date'].isin(target_dates)]
        
        if filtered_df.empty:
            print("âš ï¸ ì˜¤ëŠ˜/ë‚´ì¼/ëª¨ë ˆ ë°ì´í„°ê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê·¸ë˜í”„ ìƒì„±
        plt.figure(figsize=(12, 6))
        
        for i, target_date in enumerate(target_dates):
            day_data = filtered_df[filtered_df['date'] == target_date]
            if not day_data.empty:
                day_name = ['ì˜¤ëŠ˜', 'ë‚´ì¼', 'ëª¨ë ˆ'][i]
                plt.plot(day_data['datetime'], day_data['ì˜ˆì¸¡ë°œì „ëŸ‰(kWh)'], 
                        marker='o', linewidth=2, markersize=4, label=f'{day_name} ({target_date})')
        
        plt.title('ì‹œê°„ë³„ íƒœì–‘ê´‘ ë°œì „ëŸ‰ ì˜ˆì¸¡', fontsize=16, fontweight='bold', pad=20)
        plt.xlabel('ì‹œê°„', fontsize=12)
        plt.ylabel('ë°œì „ëŸ‰ (kWh)', fontsize=12)
        plt.legend(fontsize=10, loc='upper right')
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        plt.tight_layout()
        
        print("\nğŸ“ˆ ì‹œê°„ë³„ ë°œì „ëŸ‰ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤...")
        plt.show()
        
    except Exception as e:
        print(f"âš ï¸ ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("matplotlib ì„¤ì¹˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: pip install matplotlib")


# ==============================================================================
# ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ (Main Execution Block)
# ==============================================================================
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("--- íƒœì–‘ê´‘ ë°œì „ëŸ‰ ì˜ˆì¸¡ ì‹œì‘ ---")
    print("ì˜ˆë³´ì¼ì‹œëŠ” í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìë™ ì„¤ì •ë©ë‹ˆë‹¤.")
    
    base_date, base_time = get_latest_base_time()

    user_inputs = get_user_inputs(base_date)
    api_params = {'base_date': base_date, 'base_time': base_time, 'nx': str(user_inputs['nx']), 'ny': str(user_inputs['ny'])}
    weather_items = get_weather_forecast(api_params)
    if not weather_items: return

    processed_df = process_weather_data(weather_items, user_inputs)
    if processed_df.empty: return

    df_with_solar_pos = add_solar_position_features(processed_df.copy())
    df_with_insolation = predict_insolation(df_with_solar_pos)
    if df_with_insolation.empty: return
    
    predicted_efficiency = predict_power_generation(df_with_insolation)
    if predicted_efficiency is None: return

    capacity_mw = user_inputs['ì„¤ë¹„ìš©ëŸ‰(MW)']
    predictions_kwh = predicted_efficiency * capacity_mw * 1000

    print("\n--- ğŸŒ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ---")
    
    # --- ì—¬ê¸°ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤ ---
    # 'Predicted_Solar' ëŒ€ì‹ , ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª…ì¸ 'ì¼ì‚¬(MJ/m2)'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    result_df = df_with_insolation[['datetime', 'ê¸°ì˜¨(Â°C)', 'ìŠµë„(%)', 'íƒœì–‘ê³ ë„', 'ì¼ì‚¬(MJ/m2)']].copy()
    result_df.rename(columns={'ì¼ì‚¬(MJ/m2)': 'ì˜ˆì¸¡ì¼ì‚¬ëŸ‰(MJ/m2)'}, inplace=True)
    # --------------------------

    result_df['ì˜ˆì¸¡íš¨ìœ¨'] = np.round(predicted_efficiency, 4)
    result_df['ì˜ˆì¸¡ë°œì „ëŸ‰(kWh)'] = np.round(predictions_kwh, 2)
    
    # ìµœì¢… ê²°ê³¼ë¥¼ í†µí•©ëœ result í´ë”ì— ì €ì¥
    output_path = os.path.abspath(
        os.path.join(BASE_DIR, "..", "..", "..", "ìµœì¢…_ë°œì „ëŸ‰_ì˜ˆì¸¡_ëª¨ë¸", "result", "solar_prediction_results.csv")
    )
    # ê²°ê³¼ ë””ë ‰í„°ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    result_df['datetime'] = result_df['datetime'].dt.tz_localize(None)
    result_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"\nâœ… ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("\n=== ì‹œê°„ëŒ€ë³„ ì˜ˆì¸¡ ê²°ê³¼ (ìƒìœ„ 10ê°œ) ===")
    print(result_df.head(10).to_string())

    # ì¼ë³„ ì´ ë°œì „ëŸ‰ ê³„ì‚° ë° ì¶œë ¥
    daily_totals = calculate_daily_totals(result_df)
    print_daily_totals(daily_totals)
    
    # ì‹œê°„ë³„ ë°œì „ëŸ‰ ê·¸ë˜í”„ ì¶œë ¥
    show_hourly_generation_graph(result_df)


if __name__ == "__main__":
    main()
